{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonfile(file , readfrom, readto,meta):\n",
    "    print(\"read json\")\n",
    "    data=[]\n",
    "    metaset=set(meta.index)\n",
    "    metadic=meta.to_dict()\n",
    "    num_of_review=0\n",
    "    category_set=set()\n",
    "    with open(file) as data_f:\n",
    "        for line in data_f:\n",
    "            num_of_review = num_of_review+1\n",
    "            if num_of_review <readfrom:\n",
    "                continue\n",
    "            temp=json.loads(line)\n",
    "            if temp['asin'] in metaset :\n",
    "                if len(metadic['category'][temp['asin']])>0:\n",
    "                    #print(metadic['category'][temp['asin']])\n",
    "                    category_set.update(metadic['category'][temp['asin']])\n",
    "                    data.append(temp)\n",
    "            if num_of_review==readto:\n",
    "                break\n",
    "    df= pd.DataFrame(data)\n",
    "    category_set.discard(\"Books\")\n",
    "    return df, data,category_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_meta_jsonfile(file):\n",
    "    print(\"read meta json\")\n",
    "    data=[]\n",
    "    num_of_review=0\n",
    "    with open(file) as data_f:\n",
    "        for line in data_f:\n",
    "            data.append(json.loads(line))\n",
    "    df= pd.DataFrame(data,columns=['category','asin'])\n",
    "    df.set_index('asin',inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_morethan_N_and_review2word(n,review_lis,data):\n",
    "    print(\"read morethan N\")\n",
    "    countV = CountVectorizer(min_df=5)\n",
    "    countV.fit(review_lis)\n",
    "    print(\"after fit\")\n",
    "    cVoc=countV.vocabulary_\n",
    "    inverse_cVoc={v:k for k,v in cVoc.items()}\n",
    "    print(\"inv cvoc\")\n",
    "    formorethanN=np.zeros(shape=(len(cVoc)))\n",
    "    review2word={}\n",
    "\n",
    "        \n",
    "    for i in range(len(data)):\n",
    "        review2word[i]={}\n",
    "    for i in range(int(len(review_lis)/batch_size)+1):\n",
    "        if len(review_lis[i*batch_size:i*batch_size+batch_size])==0:\n",
    "            break\n",
    "        print('remove more than N :'+str(i)+'th')\n",
    "        temp = countV.transform(review_lis[i*batch_size:i*batch_size+batch_size]).toarray()\n",
    "        mat=temp.sum(axis=0)\n",
    "        formorethanN=formorethanN+mat\n",
    "        temp_pos=np.where(temp>0)\n",
    "        for j in range(len(temp_pos[0])):\n",
    "            if inverse_cVoc[temp_pos[1][j]] in review2word[i*batch_size + temp_pos[0][j]]:\n",
    "                review2word[i*batch_size + temp_pos[0][j]][inverse_cVoc[temp_pos[1][j]]] += temp[temp_pos[0][j],temp_pos[1][j]]\n",
    "            else:\n",
    "                review2word[i*batch_size + temp_pos[0][j]][inverse_cVoc[temp_pos[1][j]]] = temp[temp_pos[0][j],temp_pos[1][j]]        \n",
    "    del_lis=[]\n",
    "    for i in range(len(formorethanN)):\n",
    "        if formorethanN[i]>n:\n",
    "            del_lis.append(inverse_cVoc[i])\n",
    "    return del_lis ,review2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index2word(idx):\n",
    "    return inv_tfidf_voc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_wset(del_lis , review_lis,para):\n",
    "    print(\"return word set and review to word\")\n",
    "    global inv_tfidf_voc\n",
    "    tfidf = TfidfVectorizer(stop_words=del_lis,min_df=5).fit(review_lis)\n",
    "    inv_tfidf_voc = {v:k for k,v in tfidf.vocabulary_.items()}\n",
    "    words=set()\n",
    "    review2word=[]\n",
    "    for i in range(int(len(review_lis)/batch_size)+1):\n",
    "        forlessthan_tfidf=[]\n",
    "        if len(review_lis[i*batch_size:i*batch_size+batch_size])==0:\n",
    "            break\n",
    "        print('make word set: '+str(i)+'th')\n",
    "        temp = tfidf.transform(review_lis[i*batch_size:i*batch_size+batch_size]).toarray()\n",
    "        temp_pos=np.where(temp>para)\n",
    "        forupdate=list(map(index2word,temp_pos[1]))\n",
    "        for j in range(len(forupdate)):\n",
    "            words.add(forupdate[j])\n",
    "    word_li=list(words)\n",
    "    \n",
    "    return word_li,review2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_user2cate(user_lis,cate_set,data,metadic):\n",
    "    dic={}\n",
    "    for ele in user_lis:\n",
    "        dic[ele]={}\n",
    "    for line in data:\n",
    "        user = line['reviewerID']\n",
    "        item = line['asin']\n",
    "        for ele in metadic['category'][item]:\n",
    "            if ele != 'Books':\n",
    "                #print(ele,metadic['category'][item])\n",
    "                #print( dic[item])\n",
    "                if ele in dic[user]:\n",
    "                    dic[user][ele]=dic[user][ele]+1\n",
    "                else: \n",
    "                    dic[user][ele]=1\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_item2word(item_lis,word_lis,r2w,data):\n",
    "    dic={}\n",
    "    word_set=set(word_lis)\n",
    "    for ele in item_lis:\n",
    "        dic[ele]={}\n",
    "    for i in range(len(r2w)):\n",
    "        cur_r2w=r2w[i].items()\n",
    "        cur_item=data[i]['asin']\n",
    "        #print(cur_r2w)\n",
    "        for ele in cur_r2w:\n",
    "            if ele[0] in word_set:\n",
    "                if ele[0] in dic[cur_item]:\n",
    "                    dic[cur_item][ele[0]] = dic[cur_item][ele[0]]+ele[1]\n",
    "                else:\n",
    "                    dic[cur_item][ele[0]] = ele[1]\n",
    "\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_user2word(user_lis,word_lis,r2w,data):\n",
    "    dic={}\n",
    "    word_set=set(word_lis)\n",
    "    for ele in user_lis:\n",
    "        dic[ele]={}\n",
    "    for i in range(len(r2w)):\n",
    "        cur_r2w=r2w[i].items()\n",
    "        cur_id =data[i][\"reviewerID\"]\n",
    "        for ele in cur_r2w:\n",
    "            if ele[0] in word_set:\n",
    "                if ele in dic[cur_id]:\n",
    "                    dic[cur_id][ele[0]] += ele[1]\n",
    "                else:\n",
    "                    dic[cur_id][ele[0]] = ele[1]\n",
    "    return dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read meta json\n"
     ]
    }
   ],
   "source": [
    "inv_tfidf_voc=None\n",
    "meta=read_meta_jsonfile('meta_Books.json')\n",
    "file='Books_5.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read json\n",
      "number of review: 1294652\n"
     ]
    }
   ],
   "source": [
    "df,data, category_set= read_jsonfile(file,0,2000000,meta) #a줄부터 b줄까지\n",
    "print(\"number of review: \"+str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read morethan N\n",
      "after fit\n",
      "inv cvoc\n",
      "remove more than N :0th\n",
      "remove more than N :1th\n",
      "remove more than N :2th\n",
      "remove more than N :3th\n",
      "remove more than N :4th\n",
      "remove more than N :5th\n",
      "remove more than N :6th\n",
      "remove more than N :7th\n",
      "remove more than N :8th\n",
      "remove more than N :9th\n",
      "remove more than N :10th\n",
      "remove more than N :11th\n",
      "remove more than N :12th\n",
      "remove more than N :13th\n",
      "remove more than N :14th\n",
      "remove more than N :15th\n",
      "remove more than N :16th\n",
      "remove more than N :17th\n",
      "remove more than N :18th\n",
      "remove more than N :19th\n",
      "remove more than N :20th\n",
      "remove more than N :21th\n",
      "remove more than N :22th\n",
      "remove more than N :23th\n",
      "remove more than N :24th\n",
      "remove more than N :25th\n",
      "remove more than N :26th\n",
      "remove more than N :27th\n",
      "remove more than N :28th\n",
      "remove more than N :29th\n",
      "remove more than N :30th\n",
      "remove more than N :31th\n",
      "remove more than N :32th\n",
      "remove more than N :33th\n",
      "remove more than N :34th\n",
      "remove more than N :35th\n",
      "remove more than N :36th\n",
      "remove more than N :37th\n",
      "remove more than N :38th\n",
      "remove more than N :39th\n",
      "remove more than N :40th\n",
      "remove more than N :41th\n",
      "remove more than N :42th\n",
      "remove more than N :43th\n",
      "remove more than N :44th\n",
      "remove more than N :45th\n",
      "remove more than N :46th\n",
      "remove more than N :47th\n",
      "remove more than N :48th\n",
      "remove more than N :49th\n",
      "remove more than N :50th\n",
      "remove more than N :51th\n",
      "remove more than N :52th\n",
      "remove more than N :53th\n",
      "remove more than N :54th\n",
      "remove more than N :55th\n",
      "remove more than N :56th\n",
      "remove more than N :57th\n",
      "remove more than N :58th\n",
      "remove more than N :59th\n",
      "remove more than N :60th\n",
      "remove more than N :61th\n",
      "remove more than N :62th\n",
      "remove more than N :63th\n",
      "remove more than N :64th\n"
     ]
    }
   ],
   "source": [
    "batch_size=20000\n",
    "asin_lis = list(df['asin'].drop_duplicates())\n",
    "ID_lis = list(df['reviewerID'].drop_duplicates())\n",
    "review_lis =list(df['reviewText'])\n",
    "category_lis=list(category_set)\n",
    "meta_dic=meta.to_dict()\n",
    "del_lis ,review2word= remove_morethan_N_and_review2word(45000,review_lis,data)# n개 이하는 stopword로\n",
    "#print(del_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return word set and review to word\n",
      "make word set: 0th\n",
      "make word set: 1th\n",
      "make word set: 2th\n",
      "make word set: 3th\n",
      "make word set: 4th\n",
      "make word set: 5th\n",
      "make word set: 6th\n",
      "make word set: 7th\n",
      "make word set: 8th\n",
      "make word set: 9th\n",
      "make word set: 10th\n",
      "make word set: 11th\n",
      "make word set: 12th\n",
      "make word set: 13th\n",
      "make word set: 14th\n",
      "make word set: 15th\n",
      "make word set: 16th\n",
      "make word set: 17th\n",
      "make word set: 18th\n",
      "make word set: 19th\n",
      "make word set: 20th\n",
      "make word set: 21th\n",
      "make word set: 22th\n",
      "make word set: 23th\n",
      "make word set: 24th\n",
      "make word set: 25th\n",
      "make word set: 26th\n",
      "make word set: 27th\n",
      "make word set: 28th\n",
      "make word set: 29th\n",
      "make word set: 30th\n",
      "make word set: 31th\n",
      "make word set: 32th\n",
      "make word set: 33th\n",
      "make word set: 34th\n",
      "make word set: 35th\n",
      "make word set: 36th\n",
      "make word set: 37th\n",
      "make word set: 38th\n",
      "make word set: 39th\n",
      "make word set: 40th\n",
      "make word set: 41th\n",
      "make word set: 42th\n",
      "make word set: 43th\n",
      "make word set: 44th\n",
      "make word set: 45th\n",
      "make word set: 46th\n",
      "make word set: 47th\n",
      "make word set: 48th\n",
      "make word set: 49th\n",
      "make word set: 50th\n",
      "make word set: 51th\n",
      "make word set: 52th\n",
      "make word set: 53th\n",
      "make word set: 54th\n",
      "make word set: 55th\n",
      "make word set: 56th\n",
      "make word set: 57th\n",
      "make word set: 58th\n",
      "make word set: 59th\n",
      "make word set: 60th\n",
      "make word set: 61th\n",
      "make word set: 62th\n",
      "make word set: 63th\n",
      "make word set: 64th\n"
     ]
    }
   ],
   "source": [
    "t_word_lis,aa=ret_wset(del_lis,review_lis,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/dilab/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "###del_lis에 명사제외 단어를 전부 추가한다... 혹은 특징이라보기힘든단어들을 제거한다\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "pos_lis = nltk.tag.pos_tag(t_word_lis)\n",
    "filter_by_pos = set()\n",
    "for w, p in pos_lis:\n",
    "    if p in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "        filter_by_pos.add(w)\n",
    "\n",
    "word_lis = list(filter_by_pos)\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id2word=ret_user2word(ID_lis,word_lis,review2word,data)\n",
    "item2word=ret_item2word(asin_lis,word_lis,review2word,data)\n",
    "user2cate=ret_user2cate(ID_lis,category_set,data,meta_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래프 생성\n",
    "G=nx.Graph()\n",
    "for ele in asin_lis:\n",
    "    G.add_node(ele)\n",
    "for ele in ID_lis:\n",
    "    G.add_node(ele)\n",
    "for ele in word_lis:\n",
    "    G.add_node(ele)\n",
    "for ele in category_lis:\n",
    "    G.add_node(ele)\n",
    "total_pos_w=0\n",
    "total_pos_count=0\n",
    "total_neg_w=0\n",
    "total_neg_count=0\n",
    "n= []\n",
    "\n",
    "for ele in data:\n",
    "    n.append(float(ele['overall']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: Graph\\nNumber of nodes: 479752\\nNumber of edges: 36896211\\nAverage degree: 153.8137'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=np.array(n)\n",
    "mean=np.mean(temp)\n",
    "minn=9999999\n",
    "maxn=0\n",
    "for ele in data:\n",
    "    if float(ele['overall'])>3:\n",
    "        #w='positive'\n",
    "        w=1-(float(ele['overall'])-mean)/4\n",
    "        #w=0.1\n",
    "        total_pos_count+=1\n",
    "        total_pos_w+=w\n",
    "        \n",
    "    elif float(ele['overall'])<3:\n",
    "        #w=\"negative\"\n",
    "        w=1-(float(ele['overall'])-mean)/4\n",
    "        #w=2\n",
    "        total_neg_count+=1\n",
    "        total_neg_w+=w\n",
    "    else :\n",
    "        #w=\"neutral\"   \n",
    "        w=1\n",
    "    G.add_edge(ele['reviewerID'],ele['asin'],weight=w)\n",
    "\n",
    "#frequency 로\n",
    "id_pos_rate=0.2\n",
    "asin_pos_rate=0.2\n",
    "maxw=0\n",
    "minw=999999999\n",
    "for ids in ID_lis:\n",
    "    #print(id2word[ids])\n",
    "    sorted_dic=sorted(id2word[ids].items(),key=lambda x:x[1],reverse=True)\n",
    "    splitnum=int(len(sorted_dic)*id_pos_rate)\n",
    "    for i in range(splitnum):\n",
    "        #G.add_edge(ids,sorted_dic[i][0],weight='p') \n",
    "        G.add_edge(ids,sorted_dic[i][0],weight = 0.6850359109423767)\n",
    "    for i in range(splitnum,len(sorted_dic)):\n",
    "        #G.add_edge(ids,sorted_dic[i][0],weight='n') \n",
    "        G.add_edge(ids,sorted_dic[i][0],weight = 1.6449883206158211) \n",
    "\n",
    "for asi in asin_lis:        \n",
    "    sorted_asin_dic=sorted(item2word[asi].items(),key=lambda x:x[1],reverse=True)\n",
    "    #print(sorted_asin_dic)\n",
    "    splitnum=int(len(sorted_asin_dic)*asin_pos_rate)\n",
    "    #print(split)\n",
    "    for i in range(splitnum):\n",
    "        #G.add_edge(asi,sorted_asin_dic[i][0],weight='pos') \n",
    "        G.add_edge(asi,sorted_asin_dic[i][0],weight=0.6850359109423767) \n",
    "    for i in range(splitnum,len(sorted_asin_dic)):\n",
    "        #G.add_edge(asi,sorted_asin_dic[i][0],weight='neg')\n",
    "        G.add_edge(asi,sorted_asin_dic[i][0],weight=1.6449883206158211)\n",
    "    \n",
    "for asi in asin_lis:\n",
    "    for ele in meta_dic['category'][asi]:\n",
    "        if ele in category_set:\n",
    "            G.add_edge(ele,asi,weight=0.5)\n",
    "\n",
    "for ids in ID_lis:\n",
    "    sorted_id_cate=sorted(user2cate[ids].items(),key=lambda x:x[1],reverse=True)\n",
    "    total=0\n",
    "    \n",
    "    for i in range(len(sorted_id_cate)):\n",
    "        total+=sorted_id_cate[i][1]\n",
    "    \n",
    "    for i in range(len(sorted_id_cate)):\n",
    "        w= 1-((sorted_id_cate[i][1])/total)\n",
    "        \n",
    "        total_pos_w+=w\n",
    "        total_pos_count+=1\n",
    "        if w>maxw:\n",
    "            maxw=w\n",
    "        if w<minw:\n",
    "            minw=w\n",
    "        \n",
    "        G.add_edge(ids,sorted_id_cate[i][0],weight= w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from networkx.generators.small import krackhardt_kite_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_graph=G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start! [[0, 'A26PRNQYA3Y662', []]]\n",
      "0 1000000 2000000 3000000 4000000 5000000 6000000 7000000 8000000 9000000 10000000 11000000 12000000 13000000 14000000 15000000 16000000 17000000 18000000 19000000 20000000 21000000 22000000 23000000 24000000 25000000 26000000 27000000 28000000 29000000 30000000 31000000 32000000 33000000 34000000 35000000 36000000 37000000 38000000 39000000 40000000 41000000 42000000 43000000 44000000 45000000 46000000 47000000 \n",
      "\n",
      "weight:  2\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', '0307932540']\n",
      "\n",
      "weight:  2\n",
      "route:  ['A26PRNQYA3Y662', 'United States', '0307932540']\n",
      "\n",
      "weight:  2\n",
      "route:  ['A26PRNQYA3Y662', 'december', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1004NB4ADJVZ2', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1004NB4ADJVZ2', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1011OGVLL3WUE', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1011OGVLL3WUE', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A102UTTLGQ56WT', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A102UTTLGQ56WT', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A104N56GL6SX4M', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A104N56GL6SX4M', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10C8Q8V2ZQUQQ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10C8Q8V2ZQUQQ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10CE2BTIVEQLI', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10CE2BTIVEQLI', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10D23MIQ9KIXK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10D23MIQ9KIXK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10DAX20MEBMLK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10DAX20MEBMLK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10EE5GYYW94PE', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10EE5GYYW94PE', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10FH6B4ZJM0G7', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10FH6B4ZJM0G7', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10FMSRPZ9LCN6', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10FMSRPZ9LCN6', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10GWLIUQ0UZSQ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10GWLIUQ0UZSQ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10RL3T28RHIFR', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10RL3T28RHIFR', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10SNRAODA2M0A', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10SNRAODA2M0A', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10ZPWK6OGZRTR', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10ZPWK6OGZRTR', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A110X2DNG1BL6C', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A110X2DNG1BL6C', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A113ILE3BIXFKT', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A113ILE3BIXFKT', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A113Q5CKT4Z6VY', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A113Q5CKT4Z6VY', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A114F6TNCLJIK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A114F6TNCLJIK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A114XQ5NYCAL59', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A114XQ5NYCAL59', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A117W5JZH40MY3', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A117W5JZH40MY3', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A118Z2D3HG7Z14', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A118Z2D3HG7Z14', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1199BELHKA15O', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1199BELHKA15O', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11BQXTMP37M2S', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11BQXTMP37M2S', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11F4UMNLH85B', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11F4UMNLH85B', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11JJMM1JVHSO2', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11JJMM1JVHSO2', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11JYON47SBFIK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11JYON47SBFIK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11L3YX5WIDKJ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11L3YX5WIDKJ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11O595BXMKZ5D', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11O595BXMKZ5D', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11OP5YDUJILL0', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11OP5YDUJILL0', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11SQECTT7FM41', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11SQECTT7FM41', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12006ZX2HVE1O', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12006ZX2HVE1O', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1210J74SP1EM5', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1210J74SP1EM5', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12122R63P29R2', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12122R63P29R2', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A121PYKV7F7OI7', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A121PYKV7F7OI7', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1285VAMEX32AI', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1285VAMEX32AI', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A129LQK5KL33SZ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A129LQK5KL33SZ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12BP0RF4DOJN9', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12BP0RF4DOJN9', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12C62G57QGJRT', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12C62G57QGJRT', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12D2E2HCN1OFF', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12D2E2HCN1OFF', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12ECUQV0RLK25', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12ECUQV0RLK25', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12HU7QSHEF4C8', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12HU7QSHEF4C8', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12Q27ZZ7FSFH4', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12Q27ZZ7FSFH4', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12SORSEASHSKZ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12SORSEASHSKZ', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12YUGIO0EM657', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12YUGIO0EM657', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A130DT8DLAX6J0', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A130DT8DLAX6J0', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A131MQI61Z8W3T', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A131MQI61Z8W3T', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1356HD8K3SIVK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1356HD8K3SIVK', '0307932540']\n",
      "\n",
      "weight:  3\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A13DJJ92L186GA', '0307932540']\n",
      "\n",
      "\n",
      "\n",
      "weight:  1.25\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', '0307932540']\n",
      "\n",
      "weight:  1.25\n",
      "route:  ['A26PRNQYA3Y662', 'United States', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1004NB4ADJVZ2', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1004NB4ADJVZ2', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10RL3T28RHIFR', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10RL3T28RHIFR', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A117W5JZH40MY3', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11O595BXMKZ5D', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11O595BXMKZ5D', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1210J74SP1EM5', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1210J74SP1EM5', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12HU7QSHEF4C8', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12HU7QSHEF4C8', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A130DT8DLAX6J0', '0307932540']\n",
      "\n",
      "weight:  2.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A130DT8DLAX6J0', '0307932540']\n",
      "\n",
      "weight:  2.13857928617111\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10D23MIQ9KIXK', '0307932540']\n",
      "\n",
      "weight:  2.205245952837777\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1356HD8K3SIVK', '0307932540']\n",
      "\n",
      "weight:  2.25\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10CE2BTIVEQLI', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A104N56GL6SX4M', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A104N56GL6SX4M', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10DAX20MEBMLK', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10DAX20MEBMLK', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10FMSRPZ9LCN6', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10FMSRPZ9LCN6', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A110X2DNG1BL6C', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A110X2DNG1BL6C', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A114F6TNCLJIK', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A114F6TNCLJIK', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1199BELHKA15O', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11F4UMNLH85B', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11F4UMNLH85B', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11JJMM1JVHSO2', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11JJMM1JVHSO2', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11JYON47SBFIK', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11JYON47SBFIK', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12ECUQV0RLK25', '0307932540']\n",
      "\n",
      "weight:  2.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12ECUQV0RLK25', '0307932540']\n",
      "\n",
      "weight:  2.316357063948888\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12BP0RF4DOJN9', '0307932540']\n",
      "\n",
      "weight:  2.316357063948888\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12BP0RF4DOJN9', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1011OGVLL3WUE', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1011OGVLL3WUE', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10FH6B4ZJM0G7', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A117W5JZH40MY3', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11OP5YDUJILL0', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11OP5YDUJILL0', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12006ZX2HVE1O', '0307932540']\n",
      "\n",
      "weight:  2.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12006ZX2HVE1O', '0307932540']\n",
      "\n",
      "weight:  2.4135792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A118Z2D3HG7Z14', '0307932540']\n",
      "\n",
      "weight:  2.4135792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A118Z2D3HG7Z14', '0307932540']\n",
      "\n",
      "weight:  2.416666666666667\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12C62G57QGJRT', '0307932540']\n",
      "\n",
      "weight:  2.416666666666667\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12C62G57QGJRT', '0307932540']\n",
      "\n",
      "weight:  2.4385792861711098\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10D23MIQ9KIXK', '0307932540']\n",
      "\n",
      "weight:  2.4552459528377764\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10FH6B4ZJM0G7', '0307932540']\n",
      "\n",
      "weight:  2.4552459528377764\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1356HD8K3SIVK', '0307932540']\n",
      "\n",
      "weight:  2.4552459528377764\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A13DJJ92L186GA', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10CE2BTIVEQLI', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10EE5GYYW94PE', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10EE5GYYW94PE', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A1285VAMEX32AI', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1285VAMEX32AI', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12SORSEASHSKZ', '0307932540']\n",
      "\n",
      "weight:  2.5\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12SORSEASHSKZ', '0307932540']\n",
      "\n",
      "weight:  2.519348516940341\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A114XQ5NYCAL59', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A102UTTLGQ56WT', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A102UTTLGQ56WT', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10SNRAODA2M0A', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10SNRAODA2M0A', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A1199BELHKA15O', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12122R63P29R2', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12122R63P29R2', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12YUGIO0EM657', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12YUGIO0EM657', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A131MQI61Z8W3T', '0307932540']\n",
      "\n",
      "weight:  2.5385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A131MQI61Z8W3T', '0307932540']\n",
      "\n",
      "weight:  2.574293571885396\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10C8Q8V2ZQUQQ', '0307932540']\n",
      "\n",
      "weight:  2.5833333333333335\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A113ILE3BIXFKT', '0307932540']\n",
      "\n",
      "weight:  2.5833333333333335\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A113ILE3BIXFKT', '0307932540']\n",
      "\n",
      "weight:  2.6219126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11SQECTT7FM41', '0307932540']\n",
      "\n",
      "weight:  2.6219126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12Q27ZZ7FSFH4', '0307932540']\n",
      "\n",
      "weight:  2.6219126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12Q27ZZ7FSFH4', '0307932540']\n",
      "\n",
      "weight:  2.638888888888889\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A129LQK5KL33SZ', '0307932540']\n",
      "\n",
      "weight:  2.638888888888889\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A129LQK5KL33SZ', '0307932540']\n",
      "\n",
      "weight:  2.65\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10GWLIUQ0UZSQ', '0307932540']\n",
      "\n",
      "weight:  2.65\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10GWLIUQ0UZSQ', '0307932540']\n",
      "\n",
      "weight:  2.6730769230769234\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A12D2E2HCN1OFF', '0307932540']\n",
      "\n",
      "weight:  2.6730769230769234\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A12D2E2HCN1OFF', '0307932540']\n",
      "\n",
      "weight:  2.691357063948888\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A10ZPWK6OGZRTR', '0307932540']\n",
      "\n",
      "weight:  2.7171507147425387\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10C8Q8V2ZQUQQ', '0307932540']\n",
      "\n",
      "weight:  2.7330237306155545\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11SQECTT7FM41', '0307932540']\n",
      "\n",
      "weight:  2.750117747709572\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A114XQ5NYCAL59', '0307932540']\n",
      "\n",
      "weight:  2.774690397282221\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A10ZPWK6OGZRTR', '0307932540']\n",
      "\n",
      "weight:  3.0385792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A121PYKV7F7OI7', '0307932540']\n",
      "\n",
      "weight:  3.1081995393356667\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11L3YX5WIDKJ', '0307932540']\n",
      "\n",
      "weight:  3.205245952837777\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A11BQXTMP37M2S', '0307932540']\n",
      "\n",
      "weight:  3.272756501360983\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11L3YX5WIDKJ', '0307932540']\n",
      "\n",
      "weight:  3.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'Literature &amp; Fiction', 'A113Q5CKT4Z6VY', '0307932540']\n",
      "\n",
      "weight:  3.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A113Q5CKT4Z6VY', '0307932540']\n",
      "\n",
      "weight:  3.2885792861711103\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A121PYKV7F7OI7', '0307932540']\n",
      "\n",
      "weight:  3.2899766412316422\n",
      "route:  ['A26PRNQYA3Y662', 'december', '0307932540']\n",
      "\n",
      "weight:  3.3719126195044433\n",
      "route:  ['A26PRNQYA3Y662', 'United States', 'A11BQXTMP37M2S', '0307932540']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from heapq import heappush, heappop\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "count_t = 0\n",
    "inf = 999\n",
    "start = 'A26PRNQYA3Y662'\n",
    "end = '0307932540'\n",
    "k = 100\n",
    "dp_dict = defaultdict(list)\n",
    "for i in our_graph.nodes:\n",
    "    dp_dict[i] = [[inf, []] for _ in range(k)]\n",
    "heap = []\n",
    "\n",
    "def dijkstra(start, end, count_t):\n",
    "    heappush(heap, [0, start, []])\n",
    "    print(\"start!\",heap)\n",
    "    dp_dict[start][0] = [0,[]]\n",
    "    while heap:\n",
    "        if count_t%1000000 == 0:\n",
    "            print(count_t, end=' ')\n",
    "        count_t += 1\n",
    "        w, n, r = heappop(heap)\n",
    "        r = r + [n]\n",
    "        for n_n, wei in our_graph[n].items():\n",
    "            n_w = 1 + w     \n",
    "            if n_w < dp_dict[n_n][k-1][0] and n_w > 0:\n",
    "                dp_dict[n_n][k-1] = [n_w, r+[n_n]]\n",
    "                dp_dict[n_n].sort(key = lambda x:x[0]) \n",
    "                heappush(heap, [n_w, n_n, r])\n",
    "\n",
    "## 탐색 ##\n",
    "dijkstra(start, end, count_t)\n",
    "\n",
    "##  distance 출력 ##\n",
    "print('\\n')\n",
    "for i in dp_dict[end]:\n",
    "    print(\"weight: \",i[0])\n",
    "    print(\"route: \",i[1])\n",
    "    print()\n",
    "with open(start+'->'+end+'__distance__'+'.json','w') as f:\n",
    "        json.dump(dp_dict[end], f)\n",
    "\n",
    "## weight 로 sort ##\n",
    "for i in dp_dict[end]:\n",
    "    i[0] = 0\n",
    "    for j in range(len(i[1])-1):\n",
    "        i[0] += our_graph[i[1][j]][i[1][j+1]]['weight']\n",
    "dp_dict[end].sort(key = lambda x:x[0])   \n",
    "\n",
    "##  weight 출력 ##\n",
    "print('\\n')\n",
    "for i in dp_dict[end]:\n",
    "    print(\"weight: \",i[0])\n",
    "    print(\"route: \",i[1])\n",
    "    print()\n",
    "with open(start+'->'+end+'__weight__'+'.json','w') as f:\n",
    "        json.dump(dp_dict[end], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_graph=G\n",
    "import sys\n",
    "from heapq import heappush, heappop\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "count_t = 0\n",
    "inf = 999\n",
    "start = 'A26PRNQYA3Y662'\n",
    "end = '0307932540'\n",
    "k = 10\n",
    "dp_dict = defaultdict(list)\n",
    "for i in our_graph.nodes:\n",
    "    dp_dict[i] = [[inf, []] for _ in range(k)]\n",
    "heap = []\n",
    "# with open(start+'->'+end+'__distance__'+'.json','w') as f:\n",
    "#         json.dump(dp_dict[end], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "weight:  0.2\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> Literature &amp; Fiction\n",
      "Literature &amp; Fiction -> 0307932540\n",
      "\n",
      "weight:  0.2\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> United States\n",
      "United States -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> Literature &amp; Fiction\n",
      "Literature &amp; Fiction -> 2 -> A1004NB4ADJVZ2\n",
      "A1004NB4ADJVZ2 -> None -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> United States\n",
      "United States -> 2 -> A1004NB4ADJVZ2\n",
      "A1004NB4ADJVZ2 -> None -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> Literature &amp; Fiction\n",
      "Literature &amp; Fiction -> 1 -> A1011OGVLL3WUE\n",
      "A1011OGVLL3WUE -> None -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> United States\n",
      "United States -> 1 -> A1011OGVLL3WUE\n",
      "A1011OGVLL3WUE -> None -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> Literature &amp; Fiction\n",
      "Literature &amp; Fiction -> 1 -> A102UTTLGQ56WT\n",
      "A102UTTLGQ56WT -> None -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> United States\n",
      "United States -> 1 -> A102UTTLGQ56WT\n",
      "A102UTTLGQ56WT -> None -> 0307932540\n",
      "\n",
      "weight:  0.30000000000000004\n",
      "route: \n",
      "A26PRNQYA3Y662 -> 1 -> Literature &amp; Fiction\n",
      "Literature &amp; Fiction -> 1 -> A104N56GL6SX4M\n",
      "A104N56GL6SX4M -> None -> 0307932540\n",
      "\n",
      "weight:  4\n",
      "route: \n",
      "A26PRNQYA3Y662 december\n",
      "december 0307932540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# our_graph=G\n",
    "# for i in dp_dict[end]:\n",
    "#     i[0] = 0\n",
    "#     for j in range(len(i[1])-1):\n",
    "#         i[0] += our_graph[i[1][j]][i[1][j+1]]['weight']\n",
    "with open(start+'->'+end+'.json','r',encoding=\"UTF-8\") as f:\n",
    "    dp_dict[end] = json.load(f)\n",
    "    \n",
    "dp_dict[end].sort(key = lambda x:x[0])   \n",
    "\n",
    "##  weight 출력 ##\n",
    "print('\\n')\n",
    "for i in dp_dict[end]:\n",
    "    print(\"weight: \",i[0])\n",
    "    print(\"route: \")\n",
    "    for j in range(len(i[1])-1):\n",
    "        temp1=i[1][j]\n",
    "        temp2=i[1][j+1]\n",
    "        \n",
    "        if temp1 in asin_lis: \n",
    "            if temp2 in ID_lis: #item -> user\n",
    "                rate = None\n",
    "                for ele in data:\n",
    "                    if ele['reviewerID']==temp2 and ele['asin']==temp1:\n",
    "                        rate=ele['overall']\n",
    "                print(temp1,\"->\",rate,\"->\",temp2)\n",
    "            elif temp2 in category_lis: #item -> cate\n",
    "                print(temp1,\"->\",temp2)\n",
    "            elif temp2 in word_lis:    # item -> word\n",
    "                print(temp1,\"->\",item2word[temp1][temp2],\"->\",temp2)\n",
    "            \n",
    "        elif temp1 in ID_lis:\n",
    "            if temp2 in asin_lis:  # user -> item\n",
    "                rate = None\n",
    "                for ele in data:\n",
    "                    if ele['reviewerID']==temp2 and ele['asin']==temp1:\n",
    "                        rate=ele['overall']\n",
    "                print(temp1,\"->\",rate,\"->\",temp2)\n",
    "            elif temp2 in category_lis:  # user -> cate\n",
    "                print(temp1,\"->\",user2cate[temp1][temp2],\"->\",temp2)\n",
    "            elif temp2 in word_lis:    # user -> word\n",
    "                print(temp1,\"->\",id2word[temp1][temp2],\"->\",temp2)\n",
    "            \n",
    "        elif temp1 in word_lis:\n",
    "            if temp2 in ID_lis:      # word -> user\n",
    "                print(temp1,\"->\",id2word[temp2][temp1],\"->\",temp2)\n",
    "            elif temp2 in asin_lis:  # word -> item\n",
    "                 print(temp1,\"->\",item2word[temp2][temp1],\"->\",temp2)\n",
    "            \n",
    "        elif temp1 in category_lis:\n",
    "            if temp2 in ID_lis:    # cate -> user\n",
    "                print(temp1,\"->\",user2cate[temp2][temp1],\"->\",temp2)\n",
    "            elif temp2 in asin_lis:  # cate -> item\n",
    "                print(temp1,\"->\",temp2)\n",
    "                \n",
    "    print()\n",
    "with open(start+'->'+end+'__weight__'+'.json','w') as f:\n",
    "        json.dump(dp_dict[end], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
